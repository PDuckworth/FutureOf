{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONET Task Similarity Dataset\n",
    "---\n",
    "\n",
    "By Paul Duckworth 20th Sept 2017.\n",
    "\n",
    "Create a Task Similarity Matrix from ONET datasets of Tasks, DWAs, IWAs and WAs. \n",
    "\n",
    "Use Future of Work survey as Ground Truth in 1D Gaussian Process to infer over all (DWA) Tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scpd/Datasets/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import pylab as plt\n",
    "import cPickle as pickle\n",
    "from random import shuffle\n",
    "import scipy as sp\n",
    "import scipy.optimize\n",
    "%matplotlib inline\n",
    "\n",
    "datasets = '/home/'+ getpass.getuser() +'/Datasets/'\n",
    "print datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONET TASK data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19566, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/Task Statements.txt'), sep='\\t')\n",
    "tasks = tasks[['Task ID', 'Task']]\n",
    "#tasks = tasks.loc[range(20)]     # reduce the task matrix for now :)\n",
    "tasks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22838, 2) UNIQUE DWA:  2070\n",
      "   Task ID             DWA ID\n",
      "0    20461  4.A.2.a.4.I09.D03\n",
      "1    20461  4.A.4.b.6.I08.D04\n",
      "2     8823  4.A.4.b.4.I09.D02\n",
      "3     8824  4.A.4.a.2.I03.D14\n",
      "4     8825  4.A.2.a.4.I07.D09\n"
     ]
    }
   ],
   "source": [
    "#Task DWAs (detailed work activitiy code):\n",
    "taskDWA = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/Tasks to DWAs.txt'), sep='\\t')\n",
    "taskDWA = taskDWA[['Task ID', 'DWA ID']]\n",
    "\n",
    "print taskDWA.shape, \"UNIQUE DWA: \", len(taskDWA['DWA ID'].unique()) \n",
    "print taskDWA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22838, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task</th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>IWA ID</th>\n",
       "      <th>WA ID</th>\n",
       "      <th>DWA Title</th>\n",
       "      <th>IWA Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Resolve customer complaints regarding sales an...</td>\n",
       "      <td>4.A.4.a.8.I03.D05</td>\n",
       "      <td>4.A.4.a.8.I03</td>\n",
       "      <td>4.A.4.a.8</td>\n",
       "      <td>Resolve customer complaints or problems.</td>\n",
       "      <td>Respond to customer problems or inquiries.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Monitor customer preferences to determine focu...</td>\n",
       "      <td>4.A.1.a.1.I14.D04</td>\n",
       "      <td>4.A.1.a.1.I14</td>\n",
       "      <td>4.A.1.a.1</td>\n",
       "      <td>Conduct opinion surveys or needs assessments.</td>\n",
       "      <td>Collect data about consumer needs or opinions.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Direct and coordinate activities involving sal...</td>\n",
       "      <td>4.A.4.b.4.I12.D03</td>\n",
       "      <td>4.A.4.b.4.I12</td>\n",
       "      <td>4.A.4.b.4</td>\n",
       "      <td>Direct sales, marketing, or customer service a...</td>\n",
       "      <td>Direct organizational operations, activities, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Determine price schedules and discount rates.</td>\n",
       "      <td>4.A.2.b.4.I01.D06</td>\n",
       "      <td>4.A.2.b.4.I01</td>\n",
       "      <td>4.A.2.b.4</td>\n",
       "      <td>Determine pricing or monetary policies.</td>\n",
       "      <td>Develop organizational policies, systems, or p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Review operational records and reports to proj...</td>\n",
       "      <td>4.A.2.a.4.I11.D06</td>\n",
       "      <td>4.A.2.a.4.I11</td>\n",
       "      <td>4.A.2.a.4</td>\n",
       "      <td>Analyze financial records or reports to determ...</td>\n",
       "      <td>Analyze business or financial data.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Task ID                                               Task  \\\n",
       "0        1  Resolve customer complaints regarding sales an...   \n",
       "1        2  Monitor customer preferences to determine focu...   \n",
       "2        3  Direct and coordinate activities involving sal...   \n",
       "3        4      Determine price schedules and discount rates.   \n",
       "4        5  Review operational records and reports to proj...   \n",
       "\n",
       "              DWA ID         IWA ID      WA ID  \\\n",
       "0  4.A.4.a.8.I03.D05  4.A.4.a.8.I03  4.A.4.a.8   \n",
       "1  4.A.1.a.1.I14.D04  4.A.1.a.1.I14  4.A.1.a.1   \n",
       "2  4.A.4.b.4.I12.D03  4.A.4.b.4.I12  4.A.4.b.4   \n",
       "3  4.A.2.b.4.I01.D06  4.A.2.b.4.I01  4.A.2.b.4   \n",
       "4  4.A.2.a.4.I11.D06  4.A.2.a.4.I11  4.A.2.a.4   \n",
       "\n",
       "                                           DWA Title  \\\n",
       "0           Resolve customer complaints or problems.   \n",
       "1      Conduct opinion surveys or needs assessments.   \n",
       "2  Direct sales, marketing, or customer service a...   \n",
       "3            Determine pricing or monetary policies.   \n",
       "4  Analyze financial records or reports to determ...   \n",
       "\n",
       "                                           IWA Title  \n",
       "0         Respond to customer problems or inquiries.  \n",
       "1     Collect data about consumer needs or opinions.  \n",
       "2  Direct organizational operations, activities, ...  \n",
       "3  Develop organizational policies, systems, or p...  \n",
       "4                Analyze business or financial data.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(tasks, taskDWA,  how='left', left_on=['Task ID'], right_on = ['Task ID']).sort_values(by = 'Task ID')\n",
    "df = df[df['DWA ID'].notnull()]\n",
    "df['IWA ID'] = df['DWA ID'].str.slice(0,-4)    # create IWA ID\n",
    "df['WA ID'] = df['DWA ID'].str.slice(0,-8)     # create WA ID\n",
    "\n",
    "## ADD DWA and IWA titles:\n",
    "DWAref = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/DWA Reference.txt'), sep='\\t')[['DWA ID', 'DWA Title']]\n",
    "df2 = pd.merge(df, DWAref,  how='left', left_on=['DWA ID'], right_on = ['DWA ID'])\n",
    "\n",
    "IWAref = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/IWA Reference.txt'), sep='\\t')[['IWA ID', 'IWA Title']]\n",
    "df3 = pd.merge(df2, IWAref,  how='left', left_on=['IWA ID'], right_on = ['IWA ID'])\n",
    "\n",
    "cols = ['Observed Occupation', 'O*NET Occupation title', 'O*NET-SOC Code','Description']\n",
    "df3[['Task ID', 'Task', 'DWA ID', 'DWA Title', 'IWA ID', 'IWA Title', 'WA ID']]\n",
    "\n",
    "print df3.shape\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WA ID</th>\n",
       "      <th>WA Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.A.1.a.1</td>\n",
       "      <td>Getting Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.A.1.a.2</td>\n",
       "      <td>Monitor Processes, Materials, or Surroundings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.A.1.b.1</td>\n",
       "      <td>Identifying Objects, Actions, and Events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.A.1.b.2</td>\n",
       "      <td>Inspecting Equipment, Structures, or Material</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.A.1.b.3</td>\n",
       "      <td>Estimating the Quantifiable Characteristics of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       WA ID                                           WA Title\n",
       "0  4.A.1.a.1                                Getting Information\n",
       "2  4.A.1.a.2      Monitor Processes, Materials, or Surroundings\n",
       "4  4.A.1.b.1           Identifying Objects, Actions, and Events\n",
       "6  4.A.1.b.2      Inspecting Equipment, Structures, or Material\n",
       "8  4.A.1.b.3  Estimating the Quantifiable Characteristics of..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every IWA is linked to exactly one WA from the O*NET Content Model. \n",
    "# IWAs are linked to one or more DWAs; \n",
    "\n",
    "WA = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/Work Activities.txt'), sep='\\t')\n",
    "WA.rename(columns = {'Element ID':'WA ID', 'Element Name':'WA Title'}, inplace = True)\n",
    "# WA[['WA IM Value', 'WA IM SE']] = WA[['Data Value', 'Standard Error']]  # This is per Occupation. \n",
    "\n",
    "WA = WA[WA['Scale ID'] == \"IM\"][['WA ID', 'WA Title']] #, 'WA IM Value', 'WA IM SE']]\n",
    "WA.drop_duplicates(inplace=True)\n",
    "print WA.shape\n",
    "WA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22838, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task</th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>IWA ID</th>\n",
       "      <th>WA ID</th>\n",
       "      <th>DWA Title</th>\n",
       "      <th>IWA Title</th>\n",
       "      <th>WA Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Resolve customer complaints regarding sales an...</td>\n",
       "      <td>4.A.4.a.8.I03.D05</td>\n",
       "      <td>4.A.4.a.8.I03</td>\n",
       "      <td>4.A.4.a.8</td>\n",
       "      <td>Resolve customer complaints or problems.</td>\n",
       "      <td>Respond to customer problems or inquiries.</td>\n",
       "      <td>Performing for or Working Directly with the Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Monitor customer preferences to determine focu...</td>\n",
       "      <td>4.A.1.a.1.I14.D04</td>\n",
       "      <td>4.A.1.a.1.I14</td>\n",
       "      <td>4.A.1.a.1</td>\n",
       "      <td>Conduct opinion surveys or needs assessments.</td>\n",
       "      <td>Collect data about consumer needs or opinions.</td>\n",
       "      <td>Getting Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Direct and coordinate activities involving sal...</td>\n",
       "      <td>4.A.4.b.4.I12.D03</td>\n",
       "      <td>4.A.4.b.4.I12</td>\n",
       "      <td>4.A.4.b.4</td>\n",
       "      <td>Direct sales, marketing, or customer service a...</td>\n",
       "      <td>Direct organizational operations, activities, ...</td>\n",
       "      <td>Guiding, Directing, and Motivating Subordinates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Determine price schedules and discount rates.</td>\n",
       "      <td>4.A.2.b.4.I01.D06</td>\n",
       "      <td>4.A.2.b.4.I01</td>\n",
       "      <td>4.A.2.b.4</td>\n",
       "      <td>Determine pricing or monetary policies.</td>\n",
       "      <td>Develop organizational policies, systems, or p...</td>\n",
       "      <td>Developing Objectives and Strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Review operational records and reports to proj...</td>\n",
       "      <td>4.A.2.a.4.I11.D06</td>\n",
       "      <td>4.A.2.a.4.I11</td>\n",
       "      <td>4.A.2.a.4</td>\n",
       "      <td>Analyze financial records or reports to determ...</td>\n",
       "      <td>Analyze business or financial data.</td>\n",
       "      <td>Analyzing Data or Information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Task ID                                               Task  \\\n",
       "0        1  Resolve customer complaints regarding sales an...   \n",
       "1        2  Monitor customer preferences to determine focu...   \n",
       "2        3  Direct and coordinate activities involving sal...   \n",
       "3        4      Determine price schedules and discount rates.   \n",
       "4        5  Review operational records and reports to proj...   \n",
       "\n",
       "              DWA ID         IWA ID      WA ID  \\\n",
       "0  4.A.4.a.8.I03.D05  4.A.4.a.8.I03  4.A.4.a.8   \n",
       "1  4.A.1.a.1.I14.D04  4.A.1.a.1.I14  4.A.1.a.1   \n",
       "2  4.A.4.b.4.I12.D03  4.A.4.b.4.I12  4.A.4.b.4   \n",
       "3  4.A.2.b.4.I01.D06  4.A.2.b.4.I01  4.A.2.b.4   \n",
       "4  4.A.2.a.4.I11.D06  4.A.2.a.4.I11  4.A.2.a.4   \n",
       "\n",
       "                                           DWA Title  \\\n",
       "0           Resolve customer complaints or problems.   \n",
       "1      Conduct opinion surveys or needs assessments.   \n",
       "2  Direct sales, marketing, or customer service a...   \n",
       "3            Determine pricing or monetary policies.   \n",
       "4  Analyze financial records or reports to determ...   \n",
       "\n",
       "                                           IWA Title  \\\n",
       "0         Respond to customer problems or inquiries.   \n",
       "1     Collect data about consumer needs or opinions.   \n",
       "2  Direct organizational operations, activities, ...   \n",
       "3  Develop organizational policies, systems, or p...   \n",
       "4                Analyze business or financial data.   \n",
       "\n",
       "                                            WA Title  \n",
       "0  Performing for or Working Directly with the Pu...  \n",
       "1                                Getting Information  \n",
       "2    Guiding, Directing, and Motivating Subordinates  \n",
       "3               Developing Objectives and Strategies  \n",
       "4                      Analyzing Data or Information  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.merge(df3, WA, how='left', left_on=['WA ID'], right_on = ['WA ID']).sort_values(by = 'Task ID')\n",
    "# df4[df4['Task ID'].notnull()]\n",
    "print df4.shape\n",
    "\n",
    "#df4[df4['IWA ID'].str.contains('4.A.4.b.4')].drop_duplicates(subset=['IWA ID'])#.sort_values(by = 'IWA ID')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## obtain GTs from survey on Future of Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID      350\n",
      "GT Rating    350\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "survey_data = pd.read_csv(os.path.join(datasets, 'FoEmployment/fow-expert-survey/data/cleaned/counts_data_with_metadata.csv'))\n",
    "survey_data.rename(columns = {'title':'O*NET Occupation title', \n",
    "                              'Unnamed: 0': 'Task'}, inplace = True)\n",
    "\n",
    "# Change Ordinal Data to Numeric - bit hacky\n",
    "ratings = [4,3,2,1,0]\n",
    "survey_data['GT Rating'] = (survey_data['Completely Automatable Today']*ratings[0] + survey_data['Could be Mostly Automated Today (Human Still Needed)']*ratings[1] + survey_data['Mostly Not Automatable Today (Human Does Most of It)']*ratings[2] + survey_data['Not Automatable Today']*ratings[3] + survey_data['Unsure']*ratings[4]) / survey_data['Number of Responses']                \n",
    "                \n",
    "survey_data = survey_data[['Task ID', 'GT Rating']]\n",
    "print survey_data.count()\n",
    "# survey_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350, 2)\n",
      "348\n"
     ]
    }
   ],
   "source": [
    "# Do tasks overlap between occus? No probs not. merge this in... \n",
    "print survey_data.shape\n",
    "print len(survey_data['Task ID'].unique())\n",
    "# survey_data[survey_data.duplicated(subset='Task ID', keep=False) == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22840, 3)\n",
      "Instances of annotated DWA IDs:  416\n"
     ]
    }
   ],
   "source": [
    "task_dwa_rat = pd.merge(taskDWA, survey_data, how='left', left_on=['Task ID'], right_on = ['Task ID'])#.sort_values(by = 'Task ID')\n",
    "\n",
    "print task_dwa_rat.shape\n",
    "print \"Instances of annotated DWA IDs: \", sum(task_dwa_rat['GT Rating'].notnull())   # boolean \n",
    "# task_dwa_rat[task_dwa_rat['GT Rating'].notnull()].head()\n",
    "\n",
    "# task_dwa_rat[task_dwa_rat['GT Rating'].notnull()][task_dwa_rat['DWA ID'] == '4.A.4.b.4.I12.D39']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique DWAs Annotated =  (314, 3)\n"
     ]
    }
   ],
   "source": [
    "DWA_mean_rating = task_dwa_rat.groupby(['DWA ID']).mean().reset_index().rename(columns = {'GT Rating':'DWA GT Rating'})\n",
    "DWA_mean_rating.head() #[DWA_mean_rating['DWA ID'] == '4.A.4.b.4.I12.D39']\n",
    "\n",
    "print \"Unique DWAs Annotated = \", DWA_mean_rating[DWA_mean_rating['DWA GT Rating'].notnull()].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWA Level Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2070\n",
      "(2070, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DWA ID</th>\n",
       "      <th>DWA GT Rating</th>\n",
       "      <th>IWA ID</th>\n",
       "      <th>WA ID</th>\n",
       "      <th>DWA Title</th>\n",
       "      <th>IWA Title</th>\n",
       "      <th>WA Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.A.4.a.8.I03.D05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.A.4.a.8.I03</td>\n",
       "      <td>4.A.4.a.8</td>\n",
       "      <td>Resolve customer complaints or problems.</td>\n",
       "      <td>Respond to customer problems or inquiries.</td>\n",
       "      <td>Performing for or Working Directly with the Pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.A.1.a.1.I14.D04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.A.1.a.1.I14</td>\n",
       "      <td>4.A.1.a.1</td>\n",
       "      <td>Conduct opinion surveys or needs assessments.</td>\n",
       "      <td>Collect data about consumer needs or opinions.</td>\n",
       "      <td>Getting Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.A.4.b.4.I12.D03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.A.4.b.4.I12</td>\n",
       "      <td>4.A.4.b.4</td>\n",
       "      <td>Direct sales, marketing, or customer service a...</td>\n",
       "      <td>Direct organizational operations, activities, ...</td>\n",
       "      <td>Guiding, Directing, and Motivating Subordinates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.A.2.b.4.I01.D06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.A.2.b.4.I01</td>\n",
       "      <td>4.A.2.b.4</td>\n",
       "      <td>Determine pricing or monetary policies.</td>\n",
       "      <td>Develop organizational policies, systems, or p...</td>\n",
       "      <td>Developing Objectives and Strategies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.A.2.a.4.I11.D06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.A.2.a.4.I11</td>\n",
       "      <td>4.A.2.a.4</td>\n",
       "      <td>Analyze financial records or reports to determ...</td>\n",
       "      <td>Analyze business or financial data.</td>\n",
       "      <td>Analyzing Data or Information</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DWA ID  DWA GT Rating         IWA ID      WA ID  \\\n",
       "0  4.A.4.a.8.I03.D05            NaN  4.A.4.a.8.I03  4.A.4.a.8   \n",
       "1  4.A.1.a.1.I14.D04            NaN  4.A.1.a.1.I14  4.A.1.a.1   \n",
       "2  4.A.4.b.4.I12.D03            NaN  4.A.4.b.4.I12  4.A.4.b.4   \n",
       "3  4.A.2.b.4.I01.D06            NaN  4.A.2.b.4.I01  4.A.2.b.4   \n",
       "4  4.A.2.a.4.I11.D06            NaN  4.A.2.a.4.I11  4.A.2.a.4   \n",
       "\n",
       "                                           DWA Title  \\\n",
       "0           Resolve customer complaints or problems.   \n",
       "1      Conduct opinion surveys or needs assessments.   \n",
       "2  Direct sales, marketing, or customer service a...   \n",
       "3            Determine pricing or monetary policies.   \n",
       "4  Analyze financial records or reports to determ...   \n",
       "\n",
       "                                           IWA Title  \\\n",
       "0         Respond to customer problems or inquiries.   \n",
       "1     Collect data about consumer needs or opinions.   \n",
       "2  Direct organizational operations, activities, ...   \n",
       "3  Develop organizational policies, systems, or p...   \n",
       "4                Analyze business or financial data.   \n",
       "\n",
       "                                            WA Title  \n",
       "0  Performing for or Working Directly with the Pu...  \n",
       "1                                Getting Information  \n",
       "2    Guiding, Directing, and Motivating Subordinates  \n",
       "3               Developing Objectives and Strategies  \n",
       "4                      Analyzing Data or Information  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consistency check: how many DWAs are mapped up from Task to DWA (all 2070 :)\n",
    "print len(DWA_mean_rating['DWA ID'].unique())\n",
    "\n",
    "keep_columns = ['DWA ID', 'DWA GT Rating', 'IWA ID', 'WA ID', 'DWA Title', 'IWA Title', 'WA Title']\n",
    "df5 = pd.merge(df4, DWA_mean_rating, how='left', left_on=['DWA ID'], right_on = ['DWA ID'])[keep_columns].drop_duplicates(subset=keep_columns)\n",
    "print df5.shape\n",
    "# df5[df5['DWA GT Rating'].notnull()].head()\n",
    "\n",
    "df5.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into Train, Validate and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df5.reset_index()\n",
    "X = data[data['DWA GT Rating'].notnull()].reset_index(drop=True)\n",
    "test = df5[df5['DWA GT Rating'].isnull()].reset_index(drop=True)\n",
    "y = X['DWA GT Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_this = (X, test, y)\n",
    "file_name = 'tasks_by_similarity.p'\n",
    "f = open(os.path.join(datasets, 'FoEmployment/Analysis_of_ONET_Tasks', file_name), \"w\")\n",
    "pickle.dump(save_this, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314, 8)\n",
      "(283, 9)\n",
      "(283, 1)\n",
      "(31, 9)\n",
      "(31, 1)\n",
      "(1756, 8)\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "print x_train.shape\n",
    "print y_train.shape\n",
    "print x_valid.shape\n",
    "print y_valid.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_kernel(A, B, args):\n",
    "    K = np.zeros([A.shape[0], B.shape[0]])\n",
    "    \n",
    "    for index, row in A.iterrows(): \n",
    "        matchesIWA = row['IWA ID'] == B['IWA ID']\n",
    "        matchesWA = row['WA ID'] == B['WA ID']\n",
    "#         noMatch = row['IWA ID'] != B['IWA ID']\n",
    "        update_cov_row = matchesIWA*args[0] + matchesWA*args[1] # + noMatch*args[2]  # operators on bool vectors works fine\n",
    "        K[index] += update_cov_row\n",
    "    return K #((K - K.min(axis=0)) / (K.max(axis=0) - K.min(axis=0)))\n",
    "\n",
    "# why doesnt unit normalising the Kernels help? \n",
    "\n",
    "\n",
    "def gaussian_process(K, y, Ks = None, Kss = None, predict = False):\n",
    "    N = K.shape[0]\n",
    "    jitter = 1e-6\n",
    "\n",
    "    # compute the Posterior distribution (mean and covariance)\n",
    "    diag = jitter*np.eye(N)\n",
    "    flag = False\n",
    "    cnt = 0\n",
    "    while flag == False:\n",
    "        try: \n",
    "            L = np.linalg.cholesky(K+diag)\n",
    "            flag = True\n",
    "        except np.linalg.LinAlgError as e:\n",
    "            print \".\",\n",
    "            if cnt == 0: \n",
    "                print K+diag\n",
    "                print \"eigs: \", np.linalg.eig(K+diag)\n",
    "                cnt = 1\n",
    "            diag += jitter*np.eye(N)\n",
    "\n",
    "    # # solve for m where: L*m = y\n",
    "    m = np.linalg.solve(L, y)\n",
    "\n",
    "    # # solve for alpha where: L.T*alpha = m\n",
    "    alpha = np.linalg.solve(L.T, m)\n",
    "\n",
    "    LML = -0.5*np.dot(y.T, alpha) - sum(np.log(np.diag(L))) - 0.5*N*np.log(2*np.pi) # larger (negative) better\n",
    "    \n",
    "    if predict:\n",
    "        print \"predicting... \"\n",
    "        # compute the posterior mean for test points Ks\n",
    "        mu = np.dot(Ks.T, alpha)\n",
    "\n",
    "        # compute the variance at our test points\n",
    "        # solve for v where: Lv = Kstar\n",
    "        v = np.linalg.solve(L, Ks)  \n",
    "\n",
    "        var = np.diag(Kss) - np.sum(v**2, axis=0)\n",
    "        std = np.sqrt(var)\n",
    "\n",
    "        return mu, std, LML\n",
    "    return LML\n",
    "\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisation\n",
    "\n",
    "need to add this into a cross validation loop:\n",
    "\n",
    "- randomise the validation set each loop, \n",
    "\n",
    "- optimise on the trainig each loop,\n",
    "\n",
    "- evaluate RMSE each loop. :) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_to_optimise(hyp, *args):\n",
    "    sigma = hyp[-1]\n",
    "    theta = (hyp[0], hyp[1], hyp[2])\n",
    "    (x_train, y_train) = args\n",
    "    K = similarity_kernel(x_train, x_train, theta) +  sigma**2*np.eye(x_train.shape[0])   # added some gaussian Noise\n",
    "    LML = gaussian_process(K, y_train)\n",
    "    return LML[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args =  (0.8, 0.4, 0.1, 0.1)\n",
      "LML =  [-1411.87487312]\n"
     ]
    }
   ],
   "source": [
    "hyp = (0.8, 0.4, 0.1, 1e-1)    # Initial Guess: Theta and noise sigma\n",
    "print \"args = \", hyp \n",
    "LML = f_to_optimise(hyp, x_train, y_train)\n",
    "print \"LML = \", LML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimise(hyps_init, args):\n",
    "    \n",
    "    print \"optimising... \", \n",
    "#     bnds =((1, None), (0.1, None), (0.01, 1), (0.01, None))\n",
    "    bnds =((0.1, None), (0.1, None), (0.01, None))\n",
    "    \n",
    "    hyp_opt = scipy.optimize.minimize(f_to_optimise, hyps_init, args = args,  method='L-BFGS-B', bounds=bnds, options={'maxiter':1000})\n",
    "    print hyp_opt\n",
    "    print \"done\"\n",
    "    \n",
    "    return hyp_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print \"hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "args =  [ 0.1   0.1   0.01  0.01]\n",
      "LML =  [-132798.26483154]\n"
     ]
    }
   ],
   "source": [
    "hyp = hyp_opt.x\n",
    "print \"\\nargs = \", hyp \n",
    "LML = f_to_optimise(hyp, x_train, y_train)\n",
    "print \"LML = \", LML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repeat: 0 vals: [235, 254, 93, 269, 284, 241, 130, 249, 135, 230, 64, 207, 89, 251, 107, 92, 181, 155, 77, 74, 244, 36, 46, 11, 187, 45, 174, 12, 255, 265, 85]\n",
      "init params:  [ 0.55511741  0.36805448  0.00661381]\n",
      "optimising...        fun: array([-139363.12652711])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.80607783e+03,   6.31639268e+03,   2.74723726e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.88924798  0.73151953  0.04236345]\n",
      "optimising...        fun: array([-139363.12652711])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.80607783e+03,   6.31639268e+03,   2.74723726e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 24\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.80566904  0.18075879  0.01172405]\n",
      "optimising...        fun: array([-139363.12652711])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.80607783e+03,   6.31639268e+03,   2.74723726e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      ">>likes:  [-139363.12652711041, -139363.12652711041, -139363.12652711041]\n",
      "K: Ks: Kss:\n",
      "predicting... \n",
      "RMS Error is: 0.79350509158 \n",
      "\n",
      "repeat: 1 vals: [221, 198, 305, 160, 89, 310, 137, 308, 270, 294, 276, 165, 125, 267, 300, 164, 217, 54, 257, 121, 254, 313, 161, 192, 258, 299, 250, 81, 247, 266, 91]\n",
      "init params:  [ 0.94276912  0.40017457  0.03615934]\n",
      "optimising...        fun: array([-155541.72879334])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.87411676e+03,   6.48638816e+03,   3.06724596e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.52376775  0.29516314  0.00951753]\n",
      "optimising...        fun: array([-155541.72879334])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.87411676e+03,   6.48638816e+03,   3.06724596e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.56597774  0.318778    0.02484176]\n",
      "optimising...        fun: array([-155541.72879334])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.87411676e+03,   6.48638816e+03,   3.06724596e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      ">>likes:  [-155541.72879333913, -155541.72879333913, -155541.72879333913]\n",
      "K: Ks: Kss:\n",
      "predicting... \n",
      "RMS Error is: 0.604245393061 \n",
      "\n",
      "repeat: 2 vals: [67, 286, 198, 1, 247, 146, 257, 288, 308, 193, 173, 305, 160, 154, 295, 183, 248, 94, 272, 153, 130, 155, 140, 7, 274, 57, 18, 208, 278, 97, 185]\n",
      "init params:  [ 0.34929943  0.08588752  0.00745271]\n",
      "optimising...        fun: array([-141824.46580948])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.80850800e+03,   6.47968554e+03,   2.79575798e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.88021729  0.29896648  0.0187912 ]\n",
      "optimising...        fun: array([-141824.46580948])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.80850800e+03,   6.47968554e+03,   2.79575798e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.95476733  0.12268935  0.0075496 ]\n",
      "optimising...        fun: array([-141824.46580948])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.80850800e+03,   6.47968554e+03,   2.79575798e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      ">>likes:  [-141824.46580947909, -141824.46580947909, -141824.46580947909]\n",
      "K: Ks: Kss:\n",
      "predicting... \n",
      "RMS Error is: 0.661271324485 \n",
      "\n",
      "repeat: 3 vals: [98, 66, 16, 127, 264, 170, 215, 226, 237, 17, 232, 90, 284, 268, 255, 120, 171, 219, 227, 213, 308, 143, 279, 224, 299, 145, 58, 65, 288, 29, 260]\n",
      "init params:  [ 0.9036948   0.51614507  0.03553081]\n",
      "optimising...        fun: array([-144014.08502918])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.94204801e+03,   6.45686814e+03,   2.83891739e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 132\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.17397598  0.14138581  0.00438227]\n",
      "optimising...        fun: array([-144014.08502918])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.94204801e+03,   6.45686814e+03,   2.83891739e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.59236898  0.2084512   0.00102964]\n",
      "optimising...        fun: array([-144014.08502918])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.94204801e+03,   6.45686814e+03,   2.83891739e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      ">>likes:  [-144014.08502917615, -144014.08502917615, -144014.08502917615]\n",
      "K: Ks: Kss:\n",
      "predicting... \n",
      "RMS Error is: 0.717340670697 \n",
      "\n",
      "repeat: 4 vals: [134, 49, 77, 1, 151, 56, 169, 203, 309, 292, 176, 189, 115, 303, 138, 12, 21, 131, 232, 297, 172, 266, 139, 242, 107, 43, 261, 163, 144, 273, 109]\n",
      "init params:  [ 0.96043033  0.60804249  0.01362946]\n",
      "optimising...        fun: array([-165458.86296368])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  6.75150659e+01,   1.31462002e+02,   3.27582272e+07])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 84\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  1.45433634e+01,   1.00000000e-01,   1.00000000e-02])\n",
      "done\n",
      "init params:  [ 0.83329639  0.25161423  0.02087434]\n",
      "optimising...        fun: array([-166054.79668216])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  2.78004736e+03,   6.42257801e+03,   3.27582118e+07])\n",
      "  message: 'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 8\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.1 ,  0.1 ,  0.01])\n",
      "done\n",
      "init params:  [ 0.99618202  0.64940297  0.01810003]\n",
      "optimising...        fun: array([-165619.30541223])\n",
      " hess_inv: <3x3 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([  1.67614489e+03,   1.67656399e+03,   3.27600849e+07])\n",
      "  message: 'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "     nfev: 120\n",
      "      nit: 3\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([  1.69025602e+02,   1.00000000e-01,   1.00000000e-02])\n",
      "done\n",
      ">>likes:  [-165458.86296368082, -166054.79668216448, -165619.30541222656]\n",
      "K: Ks: Kss:\n",
      "predicting... \n",
      "RMS Error is: 0.553044572589 \n",
      "\n",
      "\n",
      "Average RMS = 5.47715212114\n"
     ]
    }
   ],
   "source": [
    "## Compute RMSE for a validation set with cross-val\n",
    "\n",
    "val_size = 0.1\n",
    "vis = False \n",
    "\n",
    "# Create a Validation set\n",
    "msk = [i for i in range(X.shape[0])]\n",
    "\n",
    "# when xval, restart this randomly throughout space \n",
    "multiple_hyps_inits = np.array((5, 1., 1., 1e-1)).reshape(4,1)\n",
    "\n",
    "# RMS_reps = []\n",
    "for rep in xrange(5):\n",
    "    print \"repeat:\", rep, \n",
    "    shuffle(msk)\n",
    "    \n",
    "    n_validation_set = int(np.floor(X.shape[0]*val_size))\n",
    "    print \"vals:\", msk[:n_validation_set]\n",
    "\n",
    "    ## Data: \n",
    "    x_train = X.iloc[msk[n_validation_set:]].reset_index(drop=True)\n",
    "    x_valid = X.iloc[msk[:n_validation_set]].reset_index(drop=True)\n",
    "\n",
    "    y_train = y[msk[n_validation_set:]].as_matrix().reshape(x_train.shape[0], 1)\n",
    "    y_valid = y[msk[:n_validation_set]].as_matrix().reshape(n_validation_set, 1)\n",
    "    x_test = test.reset_index(drop=True)\n",
    "\n",
    "    # Optimise using Training set - multiple restarts: \n",
    "    \n",
    "    likes, hyper_restarts, hyper_opted = [], [], []\n",
    "    args = (x_train, y_train)\n",
    "    \n",
    "    for i in xrange(3):\n",
    "        # massage the initial hyperparams: theta_3 << theta_2 < theta_1\n",
    "        hyps_init = np.random.random(3)\n",
    "        hyps_init[::-1].sort()\n",
    "        hyps_init[2] = hyps_init[2]/10.\n",
    "        hyps_init.reshape(3,1) \n",
    "        print \"init params: \", hyps_init\n",
    "        hyper_restarts.append(hyps_init)\n",
    "        \n",
    "        hyp_opt = optimise(hyps_init, args)\n",
    "      \n",
    "        # maintain output\n",
    "        hyper_opted.append(hyp_opt.x)\n",
    "        likes.append(hyp_opt.fun[0])\n",
    "    \n",
    "    print \">>likes: \", likes\n",
    "    hyp_opt = hyper_opted[np.argmin(likes)]\n",
    "    sigma = hyp_opt[-1]\n",
    "#     theta = (hyp_opt.x[0], hyp_opt.x[1], hyp_opt.x[2])\n",
    "    theta = (hyp_opt[0], hyp_opt[1])\n",
    "    \n",
    "    # Predict over the Validation set using best restarted optimised hyperparams: \n",
    "    print \"K:\",\n",
    "    K = similarity_kernel(x_train, x_train, theta) +  sigma**2*np.eye(x_train.shape[0])   # added some gaussian Noise\n",
    "    print \"Ks:\",\n",
    "    Ks = similarity_kernel(x_train, x_valid, theta)\n",
    "    print \"Kss:\"\n",
    "    Kss = similarity_kernel(x_valid, x_valid, theta)\n",
    "    mu, std, LML = gaussian_process(K, y_train, Ks, Kss, predict = True)\n",
    "\n",
    "    if vis:\n",
    "        for cnt, (index, row), in enumerate(x_valid.iterrows()):\n",
    "            print \"mean = %0.3f, std = %0.4f. Actual = %0.3f\" % (mu[cnt], std[cnt], y_valid[cnt][0])\n",
    "\n",
    "    # Compute RMSE \n",
    "    err = rmse(y_valid, mu)\n",
    "    RMS_reps.append(err)\n",
    "    print \"RMS Error is: %s \\n\" % str(err)\n",
    "\n",
    "print \"\\nAverage RMS = %s\" % str(np.mean(RMS_reps))\n",
    "\n",
    "# for cnt, (index, row), in enumerate(x_valid.iterrows()):\n",
    "#     print \"mean = %0.3f, std = %0.4f. DWA = %s\" % (mu[cnt], std[cnt], row['DWA Title'])\n",
    "# print \"\\nThis seems OK: \", max(mu)\n",
    "\n",
    "# N = K.shape[0]\n",
    "# LML = -0.5*np.dot(y.values.T, alpha) - sum(np.log(np.diag(L))) - 0.5*N*np.log(2*np.pi) # larger (negative) better\n",
    "# print LML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Checks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66588141048245342"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMS_reps_notNorm = RMS_reps[-5:]\n",
    "np.mean(RMS_reps_notNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.79784035825244359,\n",
       " 0.52736811709008236,\n",
       " 0.62630661699070478,\n",
       " 17.476195973626403,\n",
       " 10.95385738204161,\n",
       " 11.049852171576449,\n",
       " 10.161840494417493,\n",
       " 16.280309408382713,\n",
       " 0.79350509157996119,\n",
       " 0.60424539306140423,\n",
       " 0.66127132448469328,\n",
       " 0.71734067069701002,\n",
       " 0.55304457258919792]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMS_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Top 10 most and Least Automatable Inferred Task Ratings: \n",
    "appended_list = []\n",
    "for cnt, (index, row), in enumerate(test.iterrows()):\n",
    "    if row['WA ID'] in ['4.A.4.a.4','4.A.3.b.4']:   # These two WA's don't have any training data\n",
    "        continue\n",
    "    appended_list.append((mu[cnt], std[cnt], row['DWA Title'], row['WA ID']))\n",
    "\n",
    "# for i in [(y[0], y[3], y[2]) for y in sorted(appended_list, key=lambda x: x[0])[:10]]:\n",
    "#     print i\n",
    "\n",
    "# print \"\\n\"\n",
    "# for i in [(y[0], y[3], y[2]) for y in sorted(appended_list, key=lambda x: x[0])[-10:]]:\n",
    "#     print i  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 WA's are not represented in the training data - so they come out with 0 Automatability. \n",
    "print '4.A.3.b.4' in  X['WA ID'].unique()\n",
    "print '4.A.4.a.4' in  X['WA ID'].unique()\n",
    "\n",
    "print len(X['WA ID'].unique())\n",
    "print len(Xtest['WA ID'].unique())\n",
    "print len(df5['WA ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Training Set: \"\n",
    "print \"number of DWAs per IWA in training data = %0.3f\" % X.groupby(['IWA ID']).count()['DWA ID'].mean()\n",
    "# print \"number of IWAs per WA in training data = %0.3f\" % X.drop_duplicates(subset=['WA ID', 'IWA ID']).groupby(['WA ID']).count()['IWA ID'].mean()\n",
    "# print \"number of DWAs per WA in training data = %0.3f\" % X.drop_duplicates(subset=['WA ID', 'IWA ID', 'DWA ID']).groupby(['WA ID']).count()['DWA ID'].mean()\n",
    "\n",
    "# add negative penalties for sharing IWA \n",
    "\n",
    "print \"\\nTest Set: \"\n",
    "print \"number of DWAs per IWA in test data = %0.3f\" % Xtest.groupby(['IWA ID']).count()['DWA ID'].mean()\n",
    "# print \"number of IWAs per WA in test data = %0.3f\" % Xtest.drop_duplicates(subset=['WA ID', 'IWA ID']).groupby(['WA ID']).count()['IWA ID'].mean()\n",
    "# print \"number of DWAs per WA in test data = %0.3f\" % Xtest.drop_duplicates(subset=['WA ID', 'IWA ID', 'DWA ID']).groupby(['WA ID']).count()['DWA ID'].mean()\n",
    "\n",
    "# print \"\\n\"\n",
    "# print X.groupby(['IWA ID']).count()['DWA ID']\n",
    "# print Xtest.groupby(['IWA ID']).count()['DWA ID']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
