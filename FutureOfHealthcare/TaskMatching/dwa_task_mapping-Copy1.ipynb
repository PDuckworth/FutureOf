{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map each observed healthcare task onto an ONET DWA \n",
    "---\n",
    "\n",
    "- use word2vec to augment the observed task descriptions in order to propse the most similar DWAs (using a string matching function to the Tasks within the DWA). \n",
    "\n",
    "\n",
    "\n",
    "By Paul Duckworth 8th Dec 2017.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBSERVED TASK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scpd/Datasets/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import pymed\n",
    "import time\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "datasets = '/home/'+ getpass.getuser() +'/Datasets/'\n",
    "print datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observed Occupation</th>\n",
       "      <th>Task</th>\n",
       "      <th>Task ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Administrator</td>\n",
       "      <td>Medical Coding</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Administrator</td>\n",
       "      <td>Answering Phones</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Administrator</td>\n",
       "      <td>Register new Patients</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Administrator</td>\n",
       "      <td>Use Intellisense to OCR letters and pick out c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Administrator</td>\n",
       "      <td>Child immunization targets in open exeter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Observed Occupation                                               Task  \\\n",
       "0       Administrator                                     Medical Coding   \n",
       "1       Administrator                                   Answering Phones   \n",
       "2       Administrator                              Register new Patients   \n",
       "3       Administrator  Use Intellisense to OCR letters and pick out c...   \n",
       "4       Administrator          Child immunization targets in open exeter   \n",
       "\n",
       "   Task ID  \n",
       "0        0  \n",
       "1        1  \n",
       "2        2  \n",
       "3        3  \n",
       "4        4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = os.path.join(datasets, 'FoHealthcare/FOH Occupations Tasks Features Technology.xlsx')\n",
    "\n",
    "excel_doc = pd.ExcelFile(d1)\n",
    "dataset = excel_doc.parse(\"Title, Tasks, Features\").fillna(\"-\")\n",
    "dataset.rename(columns = {'Occupation title':'Observed Occupation'}, inplace = True)\n",
    "dataset['Task ID'] = dataset.index\n",
    "data = dataset[['Observed Occupation', 'Task', 'Task ID']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test dataset with added Task \"context\".\n",
    "# d2 = os.path.join(datasets, 'FoHealthcare/expanded tasks descriptions_for matching DWAs.csv')\n",
    "# data = pd.read_csv(d2)\n",
    "# data.rename(columns = {'Occupation title':'Observed Occupation', 'Task keywords/context':'Context'}, inplace = True)\n",
    "# data['Task ID'] = data.index\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed Vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical Coding\n",
      "  (0, 48)\t1\n",
      "  (0, 152)\t1\n",
      "289 [u'accounting', u'address', u'addressing', u'admin', u'administer', u'advice', u'allergy', u'ambulance', u'answer', u'answering', u'appointment', u'approve', u'arise', u'assign', u'asthma', u'attend', u'audio', u'audit', u'authority', u'blood', u'bloodpressure', u'bloods', u'body', u'bood', u'book', u'bookable', u'building', u'called', u'canal', u'care', u'caretaking', u'case', u'cases', u'certain', u'cessation', u'changes', u'chatting', u'check', u'checking', u'checks', u'checkups', u'child', u'chronic', u'cleaning', u'clinical', u'clinics', u'clinicts', u'cloud', u'coding', u'colleagues', u'comment', u'communicate', u'conditions', u'conduct', u'connected', u'connecting', u'consult', u'consultation', u'counseling', u'cqrs', u'create', u'creating', u'data', u'dbs', u'declaration', u'deductions', u'desk', u'diagnostics', u'different', u'discuss', u'distchange', u'docmail', u'docman', u'doctors', u'document', u'documents', u'does', u'ear', u'ecg', u'email', u'emails', u'emis', u'emotional', u'enhanced', u'enter', u'ereferral', u'errors', u'examination', u'examinations', u'exeter', u'extended', u'f2', u'family', u'fasting', u'finance', u'flu', u'folders', u'follow', u'form', u'forms']\n"
     ]
    }
   ],
   "source": [
    "cv1 = CountVectorizer(stop_words='english') #max_df=0.95, min_df=2, max_features=n_features))\n",
    "\n",
    "# Each Task is represented by a vector of Words over vocabulary\n",
    "observed_tf = cv1.fit_transform(data['Task'].values)\n",
    "observed_vocab = cv1.get_feature_names()\n",
    "\n",
    "print data['Task'][0]\n",
    "print observed_tf[0]\n",
    "print len(observed_vocab), observed_vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONET TASK DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all Tasks =  (19566, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task ID</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Resolve customer complaints regarding sales an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Monitor customer preferences to determine focu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Direct and coordinate activities involving sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Determine price schedules and discount rates.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Review operational records and reports to proj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Task ID                                               Task\n",
       "0        1  Resolve customer complaints regarding sales an...\n",
       "1        2  Monitor customer preferences to determine focu...\n",
       "2        3  Direct and coordinate activities involving sal...\n",
       "3        4      Determine price schedules and discount rates.\n",
       "4        5  Review operational records and reports to proj..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Task DWAs (detailed work activitiy code):\n",
    "taskDWA = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/Tasks to DWAs.txt'), sep='\\t')\n",
    "DWArefs = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/DWA Reference.txt'), sep='\\t')\n",
    "DWA_sup = taskDWA[['Task ID', 'DWA ID']].merge(DWArefs[['DWA ID', 'IWA ID', 'DWA Title']], on=['DWA ID'])\n",
    "\n",
    "# onet_tasks_dwa = onet_tasks[['Task ID', 'Task']].merge(DWA_sup, on=['Task ID'])\\\n",
    "#                                                          .sort_values(by='Task ID')\\\n",
    "#                                                          .reset_index().drop('index', axis=1)\n",
    "# print \"Merged Tasks = \", onet_tasks_dwa.shape\n",
    "\n",
    "# Just ONET Tasks\n",
    "onet_tasks = pd.read_table(os.path.join(datasets, 'ONET/databases/db2016/Task Statements.txt'), sep='\\t')\n",
    "print \"all Tasks = \", onet_tasks.shape\n",
    "onet_tasks = onet_tasks[['Task ID', 'Task']]\n",
    "\n",
    "onet_tasks=onet_tasks.sort_values(by='Task ID').reset_index().drop('index', axis=1)\n",
    "onet_tasks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONET Vocabulary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resolve customer complaints regarding sales and service.\n",
      "  (0, 9682)\t1\n",
      "  (0, 9399)\t1\n",
      "  (0, 8823)\t1\n",
      "  (0, 2125)\t1\n",
      "  (0, 2710)\t1\n",
      "  (0, 9083)\t1\n",
      "12085 [u'10', u'24', u'3d', u'4d', u'abandoned', u'abatement', u'abatements', u'abbreviations', u'abdominal', u'abilities', u'ability', u'ablation', u'able', u'abnormal', u'abnormalities', u'aboard', u'aboveground', u'abraders', u'abrading', u'abrasion', u'abrasions', u'abrasive', u'abrasives', u'abreast', u'abroad', u'abscesses', u'absence', u'absences', u'absenteeism', u'absorbers', u'absorbing', u'absorption', u'abstract', u'abstracting', u'abstracts', u'abundance', u'abuse', u'abused', u'academia', u'academic', u'academy', u'accelerant', u'accelerated', u'accelerator', u'accelerators', u'accenting', u'accept', u'acceptability', u'acceptable', u'acceptance', u'accepted', u'accepting', u'access', u'accessed', u'accesses', u'accessibility', u'accessible', u'accessing', u'accessories', u'accessory', u'accident', u'accidental', u'accidents', u'accommodate', u'accommodation', u'accommodations', u'accompaniment', u'accompanists', u'accompany', u'accompanying', u'accomplish', u'accomplished', u'accomplishing', u'accomplishment', u'accomplishments', u'accordance', u'according', u'accordingly', u'account', u'accountability', u'accountants', u'accounting', u'accounts', u'accreditation', u'accredited', u'accretions', u'accrued', u'accumulated', u'accumulation', u'accumulations', u'accumulators', u'accuracy', u'accurate', u'accurately', u'accused', u'accustom', u'accustomed', u'acetate', u'acetic', u'acetylene']\n"
     ]
    }
   ],
   "source": [
    "cv2 = CountVectorizer(stop_words='english') #max_df=0.95, min_df=2, max_features=n_features)#, )\n",
    "\n",
    "# Each Task is represented by a vector of Words over vocabulary\n",
    "onet_tf = cv2.fit_transform(onet_tasks['Task'].values)\n",
    "onet_vocab = cv2.get_feature_names()\n",
    "\n",
    "print onet_tasks['Task'][0]\n",
    "print onet_tf[0]\n",
    "print len(onet_vocab), onet_vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- https://code.google.com/archive/p/word2vec/\n",
    "- 3 million unique words and phrases that they trained on roughly 100 billion words from a Google News dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '/home/'+ getpass.getuser() +'/Software/GoogleNews-vectors-negative300.bin'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(location, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity between pairwise words in 2 vocabularies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 accounting 1 address 2 addressing 3 admin 4 administer 5 advice 6 allergy 7 ambulance 8 answer 9 answering 10 appointment 11 approve 12 arise 13 assign 14 asthma 15 attend 16 audio 17 audit 18 authority 19 blood 20 bloodpressure 21 bloods 22 body 23 bood 24 book 25 bookable 26 building 27 called 28 canal 29 care 30 caretaking 31 case 32 cases 33 certain 34 cessation 35 changes 36 chatting 37 check 38 checking 39 checks 40 checkups 41 child 42 chronic 43 cleaning 44 clinical 45 clinics 46 clinicts 47 cloud 48 coding 49 colleagues 50 comment 51 communicate 52 conditions 53 conduct 54 connected 55 connecting 56 consult 57 consultation 58 counseling 59 cqrs 60 create 61 creating 62 data 63 dbs 64 declaration 65 deductions 66 desk 67 diagnostics 68 different 69 discuss 70 distchange 71 docmail 72 docman 73 doctors 74 document 75 documents 76 does 77 ear 78 ecg 79 email 80 emails 81 emis 82 emotional 83 enhanced 84 enter 85 ereferral 86 errors 87 examination 88 examinations 89 exeter 90 extended 91 f2 92 family 93 fasting 94 finance 95 flu 96 folders 97 follow 98 form 99 forms 100 forward 101 gather 102 gathering 103 generate 104 giving 105 gp 106 gps 107 haematology 108 health 109 help 110 history 111 home 112 hours 113 human 114 hyperthyroid 115 ice 116 igpr 117 immunization 118 immunizations 119 import 120 incentive 121 incoming 122 induction 123 information 124 injections 125 insurance 126 intellisense 127 introductions 128 invoices 129 invoicing 130 iris 131 irrigate 132 irrigation 133 jab 134 jabs 135 lab 136 label 137 labels 138 labwork 139 les 140 letter 141 letters 142 lexicom 143 lis 144 local 145 locums 146 mail 147 maintain 148 making 149 manage 150 mass 151 measure 152 medical 153 medication 154 medications 155 meeting 156 meetings 157 mjog 158 months 159 moves 160 msk 161 need 162 new 163 nhs 164 nomad 165 non 166 notes 167 ocr 168 office 169 online 170 open 171 order 172 ordering 173 packs 174 pallative 175 pap 176 paper 177 paperwork 178 parts 179 patient 180 patients 181 payroll 182 pcse 183 pensions 184 phone 185 phonecall 186 phones 187 photo 188 physical 189 pick 190 post 191 practice 192 prescription 193 prescriptions 194 print 195 printed 196 private 197 problem 198 problems 199 procedure 200 process 201 provide 202 qof 203 quest 204 quicken 205 radiology 206 receptionists 207 recoding 208 reconcile 209 record 210 recorded 211 recruitment 212 referral 213 referrals 214 register 215 registrars 216 reorder 217 repeat 218 report 219 request 220 resources 221 respond 222 results 223 review 224 reviews 225 rota 226 rotas 227 run 228 runs 229 rx 230 rxs 231 sage 232 samples 233 scan 234 scanned 235 scanning 236 schedule 237 scheduling 238 scheme 239 schemes 240 search 241 searches 242 send 243 services 244 shots 245 signatures 246 similar 247 smear 248 smoking 249 social 250 software 251 staff 252 store 253 structure 254 study 255 supplies 256 support 257 surgery 258 taking 259 talk 260 talking 261 targets 262 tasks 263 technologies 264 telephone 265 test 266 tests 267 texts 268 timeslots 269 transcribe 270 travel 271 triage 272 type 273 use 274 used 275 uses 276 using 277 vaccinations 278 vials 279 visit 280 wait 281 waits 282 week 283 weight 284 work 285 workspace 286 write 287 writing 288 xero\n"
     ]
    }
   ],
   "source": [
    "word_sims = np.zeros([len(observed_vocab), len(onet_vocab)])\n",
    "for cnt, word in enumerate(observed_vocab):\n",
    "    print cnt, word,\n",
    "    ss = []\n",
    "    for j in onet_vocab:\n",
    "        s = 0.0\n",
    "        try:\n",
    "            s = model.similarity(word, j)\n",
    "            if s < 0:\n",
    "                s = 0.0\n",
    "        except:\n",
    "            pass\n",
    "        ss.append(s)       \n",
    "    word_sims[cnt] = ss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Similarity between observed tasks and ONET tasks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print onet_tasks['Task'].values[0]\n",
    "# print np.mean(word_sims[0][onet_tf[0].indices])\n",
    "# print  data['Task'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_sims[[ 40, 111,  12,  20,  35,  33,  42, 126 , 16, 113]]  #.T[[0,10]]\n",
    "# print observed_tf[0].indices\n",
    "# print onet_tf[0].indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print np.mean( word_sims[[ 5, 17]].T[[9682, 9399, 8823, 2125, 2710, 9083]])\n",
    "# sum(sum(word_sims[[ 5, 17]].T[[9682, 9399, 8823, 2125, 2710, 9083]])) / 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "# onet_tasks_dwa = onet_tasks[['Task ID', 'Sims']].merge(DWA_sup, on=['Task ID'])\\\n",
    "#                                                         .sort_values(by='Task ID')\\\n",
    "#                                                         .reset_index().drop('index', axis=1)\n",
    "        \n",
    "# x = onet_tasks_dwa.groupby(['DWA ID', 'DWA Title']).mean().reset_index()[['DWA ID', 'DWA Title', 'Sims']].sort_values(by='Sims',ascending=False)[:10]\n",
    "# x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (u'Administrator', 0, u'Medical Coding')\n",
      "1 (u'Administrator', 1, u'Answering Phones')\n",
      "2 (u'Administrator', 2, u'Register new Patients')\n",
      "3 (u'Administrator', 3, u'Use Intellisense to OCR letters and pick out certain parts of the letter')\n",
      "4 (u'Administrator', 4, u'Child immunization targets in open exeter')\n",
      "5 (u'Administrator', 5, u'Letter writing')\n",
      "6 (u'Administrator', 6, u'Provide data to GPs from pallative care meetings')\n",
      "7 (u'Administrator', 7, u'Enter data for enhanced services')\n",
      "8 (u'Administrator', 8, u'Write QOF letters or texts')\n",
      "9 (u'Administrator', 9, u'Process prescription declaration forms')\n",
      "10 (u'Administrator', 10, u'Audit form')\n",
      "11 (u'Administrator', 11, u'Work in CQRS')\n",
      "12 (u'Administrator', 12, u'Mass mail letters for checkups using DocMail')\n",
      "13 (u'Administrator', 13, u'Scan documents')\n",
      "14 (u'Administrator', 14, u'Caretaking of health record addressing changes from health authority')\n",
      "15 (u'Administrator', 15, u'Letter Scanning')\n",
      "16 (u'Deputy Practice Manager', 16, u'Recoding')\n",
      "17 (u'Deputy Practice Manager', 17, u'Clinical Staff rota')\n",
      "18 (u'Deputy Practice Manager', 18, u'Use MJOG for flu jabs and QOF clinics')\n",
      "19 (u'Deputy Practice Manager', 19, u'SAGE accounting system')\n",
      "20 (u'Deputy Practice Manager', 20, u'Use Case Notes system for data from radiology, haematology, and distchange documents')\n",
      "21 (u'Deputy Practice Manager', 21, u'Use NHS e-referral system to manage referrals send to GP then admin to create referral')\n",
      "22 (u'Deputy Practice Manager', 22, u'Reorder shots/injections/immunizations')\n",
      "23 (u'Deputy Practice Manager', 23, u'Checking for errors in paperwork')\n",
      "24 (u'Deputy Practice Manager', 24, u'Talk to doctors about incentive schemes')\n",
      "25 (u'Deputy Practice Manager', 25, u'Create timeslots for clinical/bookable hours')\n",
      "26 (u'Deputy Practice Manager', 26, u'Open Exeter system for child immunizations')\n",
      "27 (u'Deputy Practice Manager', 27, u'Book/schedule locums')\n",
      "28 (u'Deputy Practice Manager', 28, u'Admin')\n",
      "29 (u'Deputy Practice Manager', 29, u'Data work in case notes system')\n",
      "30 (u'Deputy Practice Manager', 30, u'Schedule in Rota Cloud software')\n",
      "31 (u'Deputy Practice Manager', 31, u'Data work in SAGE accounting system')\n",
      "32 (u'Deputy Practice Manager', 32, u'Generate QOF letters')\n",
      "33 (u'Deputy Practice Manager', 33, u'Practice Staff Scheduling')\n",
      "34 (u'General Practitioner', 34, u'Document patient examinations in a similar structure to this: Problem, History, examination, family history, social, comment, medication, follow up, procedure, test request, referral, document, allergy')\n",
      "35 (u'General Practitioner', 35, u'Physical examination of patient')\n",
      "36 (u'General Practitioner', 36, u'Telephone consultation')\n",
      "37 (u'General Practitioner', 37, u'Study patient medical record')\n",
      "38 (u'General Practitioner', 38, u'Giving advice to colleagues/chatting')\n",
      "39 (u'General Practitioner', 39, u'Use different technologies for body diagnostics')\n",
      "40 (u'General Practitioner', 40, u'Order tests/labwork')\n",
      "41 (u'General Practitioner', 41, u'Attend meeting of GPs to discuss cases')\n",
      "42 (u'General Practitioner', 42, u'Approve RX')\n",
      "43 (u'General Practitioner', 43, u'Review letters')\n",
      "44 (u'General Practitioner', 44, u'Write letters ')\n",
      "45 (u'General Practitioner', 45, u'Respond to tasks in medical record')\n",
      "46 (u'General Practitioner', 46, u'Write up notes from home visit in office')\n",
      "47 (u'General Practitioner', 47, u'Writing notes while talking to patient during appointment')\n",
      "48 (u'General Practitioner', 48, u'Taking notes on paper')\n",
      "49 (u'Healthcare Assistant', 49, u'Cleaning workspace after every patient')\n",
      "50 (u'Healthcare Assistant', 50, u'Gather blood samples')\n",
      "51 (u'Healthcare Assistant', 51, u'Print out lab test labels in ICE')\n",
      "52 (u'Healthcare Assistant', 52, u'Irrigate ear canal')\n",
      "53 (u'Healthcare Assistant', 53, u'Conduct ECG')\n",
      "54 (u'Healthcare Assistant', 54, u'Emotional support during blood gathering')\n",
      "55 (u'Healthcare Assistant', 55, u'Send ECG results to GP/get signatures')\n",
      "56 (u'Healthcare Assistant', 56, u'write notes into health record from ECG and bloods')\n",
      "57 (u'Pharmacy technician', 57, u'Reconcile RXs')\n",
      "58 (u'Pharmacy technician', 58, u'Process nomad packs')\n",
      "59 (u'Phlebotomist', 59, u'Measure weight')\n",
      "60 (u'Phlebotomist', 60, u'Measure bloodpressure')\n",
      "61 (u'Phlebotomist', 61, u'Administer flu jab')\n",
      "62 (u'Phlebotomist', 62, u'Label blood vials')\n",
      "63 (u'Phlebotomist', 63, u'Cleaning workspace after every patient')\n",
      "64 (u'Phlebotomist', 64, u'Gather blood samples')\n",
      "65 (u'Practice manager', 65, u'Problems that arise with building ')\n",
      "66 (u'Practice Manager', 66, u'Connecting human resources/making introductions')\n",
      "67 (u'Practice manager', 67, u'Data work in CQRS')\n",
      "68 (u'Practice manager', 68, u'Data work in Open EXETER')\n",
      "69 (u'Practice manager', 69, u'Data work in MJOG')\n",
      "70 (u'Practice manager', 70, u'Data work in QUEST ')\n",
      "71 (u'Practice manager', 71, u'Invoicing')\n",
      "72 (u'Practice manager', 72, u'PCSE system (for pensions and ordering supplies)')\n",
      "73 (u'Practice manager', 73, u'Online finance')\n",
      "74 (u'Practice manager', 74, u'Meetings/human resources')\n",
      "75 (u'Practice manager', 75, u'Data work in PCSE/Pensions')\n",
      "76 (u'Practice manager', 76, u'Ordering supplies ')\n",
      "77 (u'Practice manager', 77, u'Data work is LES/LIS incentive scheme')\n",
      "78 (u'Practice manager', 78, u'Staff recruitment')\n",
      "79 (u'Practice manager', 79, u'Ordering immunizations')\n",
      "80 (u'Practice nurse', 80, u'Review test results ')\n",
      "81 (u'Practice nurse', 81, u'Travel vaccinations')\n",
      "82 (u'Practice nurse', 82, u'Ear canal irrigation')\n",
      "83 (u'Practice nurse', 83, u'Gather blood samples')\n",
      "84 (u'Practice nurse', 84, u'Consult with patients on medications')\n",
      "85 (u'Practice nurse', 85, u'Review patients record before appointment')\n",
      "86 (u'Practice nurse', 86, u'Document patient examinations')\n",
      "87 (u'Practice nurse', 87, u'Smoking cessation clinics (counseling/administer medications)')\n",
      "88 (u'Practice nurse', 88, u'Administer pap smear')\n",
      "89 (u'Receptionist', 89, u'Process deductions (when a patient moves from the surgery)')\n",
      "90 (u'Receptionist', 90, u'Register new patients')\n",
      "91 (u'Receptionist', 91, u'Comment in EMIS tasks to communicate to other receptionists ')\n",
      "92 (u'Receptionist', 92, u'Run search in EMIS for medication reviews more than three months')\n",
      "93 (u'Receptionist', 93, u'Run searches in EMIS for repeat RXs: asthma and hyperthyroid ')\n",
      "94 (u'Receptionist', 94, u'Scan letters')\n",
      "95 (u'Receptionist', 95, u'Send texts for asthma clinicts and other chronic conditions')\n",
      "96 (u'Receptionist', 96, u'Answer phone')\n",
      "97 (u'Receptionist', 97, u'Print letters')\n",
      "98 (u'Receptionist', 98, u'Store RXs in email to different folders')\n",
      "99 (u'Receptionist', 99, u'Process post')\n",
      "100 (u'Receptionist', 100, u'Create rota for other receptionists')\n",
      "101 (u'Receptionist', 101, u'Create letters for fasting bood test, out of hours, results, need a RX')\n",
      "102 (u'Receptionist', 102, u'Order ambulance')\n",
      "103 (u'Receptionist', 103, u'Triage and assign letters to other receptionists')\n",
      "104 (u'Receptionist', 104, u'Assign prescriptions to doctors after checking them')\n",
      "105 (u'Receptionist', 105, u'Schedule/book patients ')\n",
      "106 (u'Receptionist', 106, u'Creating tasks from letters and RX in docman/emis')\n",
      "107 (u'Receptionist', 107, u'Check incoming emails to surgery email address, forward emails')\n",
      "108 (u'Receptionist', 108, u'Attend to front desk')\n",
      "109 (u'Scanning Clerk', 109, u'Scan documents and import into health record')\n",
      "110 (u'Secretary', 110, u'Transcribe audio recorded letters')\n",
      "111 (u'Secretary', 111, u'Use Lexicom software to manage letters')\n",
      "112 (u'Secretary', 112, u'Type letters')\n",
      "113 (u'Secretary', 113, u'Write two week wait letters')\n",
      "114 (u'Secretary', 114, u'Quicken for invoicing')\n",
      "115 (u'Secretary', 115, u'Use system called Xero that does invoices ')\n",
      "116 (u'Secretary', 116, u'Runs DBS checks')\n",
      "117 (u'Secretary', 117, u'Use iGPR system connected to system one, used for private insurance')\n",
      "118 (u'Secretary', 118, u'uses ereferral system and local system (have photo of referrals)')\n",
      "119 (u'Secretary', 119, u'Payroll in system called IRIS')\n",
      "120 (u'Secretary', 120, u'Process audit paperwork for extended hours')\n",
      "121 (u'Secretary', 121, u'Induction rotas for registrars and f2 doctors')\n",
      "122 (u'Secretary', 122, u'Rotas for non clinical staff and non receptionists')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 (u'Secretary', 123, u'manage surgery email')\n",
      "124 (u'Secretary', 124, u'Help with scheduling')\n",
      "125 (u'Secretary', 125, u'Write medical report letters')\n",
      "126 (u'Secretary', 126, u'Scan physical information into docman')\n",
      "127 (u'Secretary', 127, u'MSK Forms have to be printed from email and then scanned')\n",
      "128 (u'Secretary', 128, u'Reconcile information with a phonecall')\n",
      "129 (u'Secretary', 129, u'Maintain book for 2 week waits (paper process)')\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "## Output Format:\n",
    "n_keep_dwas = 40 \n",
    "columns = ['Occupation', 'Task ID', 'Task', 'DWA Title', 'Please Select', 'Relevance \\nScore', 'DWA ID'] \n",
    "xls_path = os.path.join(datasets, 'FoHealthcare/recommended_DWA_matches.xlsx')\n",
    "writer = pd.ExcelWriter(xls_path, engine='xlsxwriter')\n",
    "\n",
    "## Big Loop over the observed Tasks\n",
    "for task_cnt, obs_task in enumerate(observed_tf):  \n",
    "#     if task_cnt > 2: continue\n",
    "    \n",
    "    print task_cnt, \n",
    "    \n",
    "    ## Get rows corresponding to the observed task\n",
    "    row_inds = obs_task.indices\n",
    "    \n",
    "    onet_similarities = []\n",
    "    for onet_task in onet_tf:\n",
    "        \n",
    "        ## Get the columns corresponding to the words in the ONET tasks\n",
    "        cols = onet_task.indices\n",
    "        onet_similarities.append(np.mean(word_sims[row_inds].T[cols]))\n",
    "        \n",
    "    ## Merge (Overwrite) the similarity of the observed task onto the ONET dataframe\n",
    "    onet_tasks['Sims'] = onet_similarities\n",
    "\n",
    "    ## Merge DWA attributes on\n",
    "    onet_tasks_dwa = onet_tasks[['Task ID', 'Sims']].merge(DWA_sup, on=['Task ID'])\\\n",
    "                                                            .sort_values(by='Task ID')\\\n",
    "                                                            .reset_index().drop('index', axis=1)\n",
    "\n",
    "    ## Average Similarity over DWAs\n",
    "    x = onet_tasks_dwa.groupby(['DWA ID', 'DWA Title']).mean()\\\n",
    "                                                    .reset_index()\\\n",
    "                                                    [['DWA ID', 'DWA Title', 'Sims']]\\\n",
    "                                                    .sort_values(by='Sims',ascending=False)[:n_keep_dwas]\n",
    "\n",
    "    observed_task = data['Task'].values[task_cnt]\n",
    "    observed_occu = data['Observed Occupation'].values[task_cnt]\n",
    "    observed_id = data['Task ID'].values[task_cnt]\n",
    "    \n",
    "    print (observed_occu, observed_id, observed_task)\n",
    "    ## Create the first output row: \n",
    "    ms = [(observed_occu, observed_id, observed_task, \n",
    "           x['DWA Title'].values[0], \"-\", x['Sims'].values[0], x['DWA ID'].values[0] )] \n",
    "\n",
    "    ## Create the subsequent output rows: \n",
    "    for cnt, (i, dwa_id, dwa, s) in enumerate(x.itertuples()):\n",
    "        if cnt == 0: continue\n",
    "\n",
    "        ms.extend([('-', '-', '-',\n",
    "            x['DWA Title'].values[cnt], \"-\",  x['Sims'].values[cnt], \n",
    "            x['DWA ID'].values[cnt] )])\n",
    "\n",
    "    ## Create a tab in the excel document \n",
    "    df_ = pd.DataFrame(data = np.array(ms), columns=columns)\n",
    "    df_.to_excel(writer, '%s' % task_cnt)\n",
    "    \n",
    "    ## Format the Excel Sheet: \n",
    "    workbook  = writer.book\n",
    "    format = workbook.add_format()\n",
    "    format.set_text_wrap() # wraps text\n",
    "\n",
    "    worksheet = writer.sheets['%s' % task_cnt]\n",
    "    worksheet.set_row(0, 30)  # set the height of the first row\n",
    "    worksheet.set_row(1, 70)  # set the height of the first row\n",
    "    \n",
    "    worksheet.set_column('A:A', 5, format)  #formats a column and specifies width\n",
    "    worksheet.set_column('B:B', 20, format)\n",
    "    worksheet.set_column('C:C', 10, format)\n",
    "    worksheet.set_column('D:D', 45, format)\n",
    "    worksheet.set_column('E:E', 60, format)\n",
    "    worksheet.set_column('F:F', 10, None)\n",
    "    worksheet.set_column('G:G', 10, None)\n",
    "    worksheet.set_column('H:H', 10, None)\n",
    "    \n",
    "writer.save()\n",
    "print \"finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list1, list2 = zip(*sorted(zip(matched_tasks[t], onet_tasks['Task'].values), reverse=True))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
